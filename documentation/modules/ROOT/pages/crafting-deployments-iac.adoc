= Preparing the ZTP GitOps Pipeline
include::_attributes.adoc[]
:profile: 5g-ran-lab

In RAN environments we will be managing thousands of Single Node OpenShift (SNO) instances, and as such, a scalable and manageable way of defining our infrastructure is required.

By describing our infrastructure as code (IaC) the Git repository holds declarative state of the fleet. 

[#introduction-to-clusterinstance]
== Introduction to the ClusterInstance

The `ClusterInstance` is an abstraction layer on top of the different components managed by the link:ztp-at-scale.html#siteconfig[SiteConfig Operator], responsible for deploying OpenShift clusters using either the {ai-workflow}[Agent Based Installation] or {ibi-docs}[Image Based Installation] flow. For the ones familiar with the {ai-workflow}[Agent Based Installation] and particularly with the `Assisted Service`, you will know that in order to deploy a cluster using this service there are several Kubernetes objects that need to be created like: `ClusterDeployment`, `InfraEnv`, `AgentClusterInstall`, etc.

The ClusterInstance simplifies this process by providing a unified structure to describe the cluster deployment configuration in a single place. In this {example-sno-clusterinstance-link}[link] you can find an example of a ClusterInstance for a SNO deployment. 

In the comming sections, we will create our own ClusterInstances using the {ibi-docs}[Image Based Installation] and {ai-workflow}[Agent Based Installation] flows to deploy a couple of SNO clusters in our lab environment.

WARNING: In the e-mail you received with the credentials to access the lab, do not forget to add the line included to your workstation’s /etc/hosts for accessing the lab environment.

IMPORTANT: The steps below rely on the lab environment being up and running.

[#git-repository]
== Git Repository

We need a Git repository where we will store our clusters configurations, we will create a new Git repository in the link:lab-environment-introduction.html#git-server[Git server] running on the infrastructure node.

1. Login into the http://infra.5g-deployment.lab:3000/[Git server] (user: student, password: student).
2. You will see that two Git repositories already exist, you **must not** change these repositories, instead you will create a new one.
+
image::gitea-repository.png[Gitea Repository]
+
3. Click on the "+" next to `Repositories`.
4. Use `ztp-repository` as `Repository Name` and click on `Create Repository`.
5. You will get redirected to the new repository page.

Now that we have a repository ready to be used we will clone it to the infrastructure host.

IMPORTANT: Below commands must be executed from the workstation host if not specified otherwise.

[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
mkdir -p ~/5g-deployment-lab/
git clone http://student:student@infra.5g-deployment.lab:3000/student/ztp-repository.git ~/5g-deployment-lab/ztp-repository/
-----

We're ready to start working in the Git repository folder structure.

As we saw in link:deployment-considerations.html#git-repo-structure[Git Repository Structure] section, the Git repository we will be using will have the following structure:

[console-input]
[source,console,subs="attributes+,+macros"]
-----
├── site-configs
│   ├── hub-1
|   |   └── extra-manifest
|   |   └── reference-manifest
|   |   |   └── {lab-major-version}
│   ├── pre-reqs
│   │   └── sno2
|   |   └── sno3
│   └── resources
└── site-policies
    ├── fleet
    │   ├── active
    |   │   └── source-crs
    |   |   |   └── reference-crs
    |   |   |   └── custom-crs
    │   └── testing
    └── sites
        └── hub-1
-----

Let's replicate it:

WARNING: If it is the first time that you are using `git` in your machine, a message requiring you to setup a Git Username and Email may be shown.

IMPORTANT: The cluster name for the SNO that we will be deploying using the agent-based install will be **sno2**. On the other hand, **sno3** is the name of the cluster that we will deploy using the image-based install flow. That's why those folder exists in the repository structure that we are creating.

[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
cd ~/5g-deployment-lab/ztp-repository/
mkdir -p site-configs/{hub-1,resources,pre-reqs/sno2,pre-reqs/sno3,hub-1/extra-manifest,reference-manifest/{lab-major-version}}
mkdir -p site-policies/{fleet/active/source-crs/reference-crs,fleet/active/source-crs/custom-crs,fleet/testing,sites/hub-1}
touch site-configs/{hub-1,resources,pre-reqs/sno2,pre-reqs/sno3,hub-1/extra-manifest,reference-manifest/{lab-major-version}}/.gitkeep
touch site-policies/{fleet/active/source-crs/reference-crs,fleet/active/source-crs/custom-crs,fleet/testing,sites/hub-1}/.gitkeep
git add --all
git commit -m 'Initialized repo structure'
git push origin main
-----

[#deploying-ztp-gitops-pipeline]
== Deploying the ZTP GitOps Pipeline

As we saw in previous sections, clusters are deployed using the ZTP GitOps Pipeline, but before starting we need to load it into our hub cluster.

We already have created the Git repository that will be used for storing our Infrastructure as Code (IaC) and Configuration as Code (CaC). Next step is deploying the ZTP GitOps Pipeline, let's do it.

IMPORTANT: Below commands must be executed from the infrastucture host if not specified otherwise.

Before continuing, make sure you have the following tooling installed in your workstation:

* {ocp-cli-docs}[oc client].
* https://podman.io/getting-started/installation[podman].

In the infrastructure server, run the following command to extract the pipeline installation files:

WARNING: If you get `ERRO[0000] running `/usr/bin/newuidmap 51706 0 1000 1 1 100000 65536`: newuidmap: write to uid_map failed: Operation not permitted` when running podman commands, run them with sudo.

[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
mkdir -p ~/5g-deployment-lab/ztp-pipeline/argocd
podman login infra.5g-deployment.lab:8443 -u admin -p r3dh4t1! --tls-verify=false
podman run --log-driver=none --rm --tls-verify=false {ztp-sitegenerate-disconnected-image} extract /home/ztp/argocd --tar | tar x -C ~/5g-deployment-lab/ztp-pipeline/argocd/
-----

Now that we extracted the pipeline content we need to get it applied to our hub cluster:

1. Login into the hub cluster.
+
CAUTION: The command below must be changed to use the OpenShift admin password provided in the e-mail you received when the lab was ready.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
oc --kubeconfig ~/hub-kubeconfig login -u admin -p <admin_password> https://api.hub.5g-deployment.lab:6443 --insecure-skip-tls-verify=true
-----
+
2. Modify the ZTP GitOps Pipeline configuration to match our environment configuration.
.. Change the repository url for the two ArgoApps:
+
NOTE: If you're using MacOS and you're getting errors while running `sed -i` commands, make sure you are using `gsed`. If you do not have it available, please install it: `brew install gnu-sed`.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
sed -i "s|repoURL: .*|repoURL: http://infra.5g-deployment.lab:3000/student/ztp-repository.git|" ~/5g-deployment-lab/ztp-pipeline/argocd/deployment/clusters-app.yaml
sed -i "s|repoURL: .*|repoURL: http://infra.5g-deployment.lab:3000/student/ztp-repository.git|" ~/5g-deployment-lab/ztp-pipeline/argocd/deployment/policies-app.yaml
-----
+
.. Change the repository path for the two ArgoApps:
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
sed -i "s|path: .*|path: site-configs|" ~/5g-deployment-lab/ztp-pipeline/argocd/deployment/clusters-app.yaml
sed -i "s|path: .*|path: site-policies|" ~/5g-deployment-lab/ztp-pipeline/argocd/deployment/policies-app.yaml
-----
+
.. Change the repository branch for the two ArgoApps:
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
sed -i "s|targetRevision: .*|targetRevision: main|" ~/5g-deployment-lab/ztp-pipeline/argocd/deployment/clusters-app.yaml
sed -i "s|targetRevision: .*|targetRevision: main|" ~/5g-deployment-lab/ztp-pipeline/argocd/deployment/policies-app.yaml
-----
+
3. Allow `ClusterImageSet` resource to the list of allowed resources:
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
sed -i "/clusterResourceWhitelist:/a \ \ - group: \'hive.openshift.io\'\n \ \ \ kind: ClusterImageSet" ~/5g-deployment-lab/ztp-pipeline/argocd/deployment/app-project.yaml
-----
+
4. Include `openshift-adp` namespace in the list of namespaces managed by the GitOps operator.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
sed -i "/destinations:/a \ \ - namespace: \'openshift-adp\'\n \ \ \ server: '\*\'" ~/5g-deployment-lab/ztp-pipeline/argocd/deployment/policies-app-project.yaml
-----
+
5. Apply the ZTP GitOps Pipeline configuration:
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
oc --kubeconfig ~/5g-deployment-lab/hub-kubeconfig apply -k ~/5g-deployment-lab/ztp-pipeline/argocd/deployment/
-----

At this stage, we have our ZTP GitOps pipeline running and waiting for commiting declarative Infrastructure and Configuration as Code to the `ztp-repository` Git repository. In the next image, a couple of new ArgoCD apps running:

* **clusters**. It is responsible for managing the deployment of Single Node OpenShift clusters from the Git repository.
* **policies**. It is responsible for managing the configuration via RHACM policies that will be applied to Single Node OpenShift clusters. Basically, it configures the {rds-config}[Telco RAN DU reference configuration]. 


image::ztp-pipeline-01.png[ZTP pipeline]

IMPORTANT: Notice that there is nothing to deploy in any of the previous ArgoCD applications. This is because we did not yet commit any configuration to the ztp-repository Git repo. This is going to change in the next section.

image::ztp-pipeline-clusters.png[ZTP clusters app]


image::ztp-pipeline-policies.png[ZTP policies app]
